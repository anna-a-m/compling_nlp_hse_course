{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00fad453",
   "metadata": {},
   "source": [
    "# Домашнее задание № 4. Языковые модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d056af4",
   "metadata": {},
   "source": [
    "## Задание 1 (8 баллов)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f532a8",
   "metadata": {},
   "source": [
    "В семинаре для генерации мы использовали предположение Маркова и считали, что слово зависит только от 1 предыдущего слова. Но ничто нам не мешает попробовать увеличить размер окна и учитывать два или даже три прошлых слова. Для них мы еще сможем собрать достаточно статистик и, логично предположить, что качество сгенерированного текста должно вырасти."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de743d1d",
   "metadata": {},
   "source": [
    "Попробуйте сделать языковую модель, которая будет учитывать два предыдущих слова при генерации текста.\n",
    "Сгенерируйте несколько текстов (3-5) и расчитайте перплексию получившейся модели. \n",
    "Можно использовать данные из семинара или любые другие (сопоставимые или большие по объему). Перплексию рассчитывайте на 10-50 отложенных предложениях (они не должны использоваться при сборе статистик).\n",
    "\n",
    "\n",
    "Подсказки:  \n",
    "    - нужно будет добавить еще один тэг <start>  \n",
    "    - еще одна матрица не нужна, можно по строкам хранить биграмы, а по колонкам униграммы  \n",
    "    - тексты должны быть очень похожи на нормальные (если у вас получается рандомная каша, вы что-то делаете не так). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296a23d5",
   "metadata": {},
   "source": [
    "### Считываем данные\n",
    "\n",
    "Будем использовать новостной корпус Ленты ру и немного (около 300 текстов) статей The Village за 20-ый год."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d078056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenta_ru = open('lenta.txt', encoding='utf-8').read()\n",
    "the_village = open('village.txt', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c619c197",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_corpus = ''.join([the_village, lenta_ru])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dee679",
   "metadata": {},
   "source": [
    "### Обрабатываем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6afcef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d6d378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    normalized_text = [word.text.strip(punctuation) for word in razdel_tokenize(text)]\n",
    "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20]\n",
    "    return normalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7847f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrammer(tokens, n=2):\n",
    "    ngrams = []\n",
    "    for i in range(0, len(tokens) - n + 1):\n",
    "        ngrams.append(' '.join(tokens[i: i + n]))\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39c541a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 103372/103372 [00:29<00:00, 3536.37it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences_news = [['<start>', '<start>'] + normalize(text) + ['<end>'] for text in tqdm(sent_tokenize(news_corpus))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d572f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams_news = Counter()\n",
    "bigrams_news = Counter()\n",
    "trigrams_news = Counter()\n",
    "\n",
    "for sentence in sentences_news:\n",
    "    unigrams_news.update(sentence)\n",
    "    bigrams_news.update(ngrammer(sentence))\n",
    "    trigrams_news.update(ngrammer(sentence, n=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3938a207",
   "metadata": {},
   "source": [
    "Матрица биграмы на слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70167fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_news_bi = lil_matrix((len(bigrams_news), \n",
    "                        len(unigrams_news)))\n",
    "\n",
    "id2word_news = list(unigrams_news)\n",
    "word2id_news = {word:i for i, word in enumerate(id2word_news)}\n",
    "\n",
    "id2bigram_news = list(bigrams_news)\n",
    "bigram2id_news = {word:i for i, word in enumerate(id2bigram_news)}\n",
    "\n",
    "for ngram in trigrams_news:\n",
    "    i = (ngram[::-1].index(' ') + 1) * -1\n",
    "    bigram = ngram[:i]\n",
    "    unigram = ngram[i + 1:]\n",
    "    bi_ind = bigram2id_news[bigram]\n",
    "    uni_ind = word2id_news[unigram]\n",
    "    matrix_news_bi[bi_ind, uni_ind] = (trigrams_news[ngram] / bigrams_news[bigram])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518b15f7",
   "metadata": {},
   "source": [
    "### Функции генерации\n",
    "\n",
    "Добавлено немного больших букв и точек, чтобы предложения выглядели симпатичнее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb69c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bi(matrix, id2word, id2bigram, bigram2id, start, n=100):\n",
    "    text = []\n",
    "    current_idx = bigram2id[start]\n",
    "    upper = False\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        # получаем продолжение новой биграмы\n",
    "        # если вероятность получить биграму слишком мала, ставим ... и выходим из цикла\n",
    "        try:\n",
    "            chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx].toarray()[0])\n",
    "        except ValueError:\n",
    "            text.append('...')\n",
    "            break\n",
    "        token = id2word[chosen]\n",
    "        # создаем новую биграму\n",
    "        new_token = id2bigram[current_idx].split()[1] + ' ' + token\n",
    "        # добавляем только продолжение биграмы\n",
    "        if upper:\n",
    "            text.append(token.title())\n",
    "            upper = False\n",
    "        elif token == '<end>':\n",
    "            text.extend(['.', token])\n",
    "            new_token = '<start> <start>'\n",
    "            upper = True\n",
    "        else:\n",
    "            text.append(token)\n",
    "        # обновляем индекс биграмы\n",
    "        current_idx = bigram2id[new_token]\n",
    "    \n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3556f6e9",
   "metadata": {},
   "source": [
    "### Эксперименты\n",
    "\n",
    "Примеры текстов для стартового токена и начала предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "690faa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Как сообщает associated press 11 из 12 двигателей обсерватории работают нормально . \n",
      "Особое внимание на то законных оснований . \n",
      "Полные имена не разглашаются но уже в среду единственный регистратор доменных имен станет обычной практикой и не отвечал ни на один маникюр с покрытием у нас с мужем . \n",
      "Учтено было также объявлено что компания выступавшая и выступающая гарантом по части 3 статьи 46 федерального закона об охране подземных коммуникаций города сообщает радиостанция эхо москвы . \n",
      "Расход этих средств россии осталось выплатить около 230 миллионов абонентов сетей gsm . \n",
      "От удара подвесной топливный бак самолета получил повреждение произошло возгорание топлива в россии кто\n"
     ]
    }
   ],
   "source": [
    "print('Как сообщает', generate_bi(matrix_news_bi, id2word_news, id2bigram_news,\n",
    "                                  bigram2id_news, start='как сообщает', n=100).replace('<end>', '\\n').replace('\\n ', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ffc1401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Последние новости о своем выходе из тюрьмы . \n",
      "Цик рассмотрел также результаты дополнительной проверки проводки которая была сделана операция . \n",
      "Другой причиной катастрофы называлась акция итальянских диверсантов которые якобы планировали совершить теракты на железной дороге . \n",
      "Проще если воспринимать его не обнародовать имена иранских агентов поскольку их функции ограничены . \n",
      "Как сообщил риа новости со ссылкой на департамент правительственной информации рассеянные силы бандитов пытаются уйти в отставку с поста главы партии шинн фейн джерри адамс лидер наиболее радикально настроенного крыла ира шинн фейн уже заявил о своем уходе с российского рынка объясняются тем что сегодня нет человека который некогда считался самым богатым\n"
     ]
    }
   ],
   "source": [
    "print('Последние новости', generate_bi(matrix_news_bi, id2word_news, id2bigram_news,\n",
    "                                  bigram2id_news, start='последние новости', n=100).replace('<end>', '\\n').replace('\\n ', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7caeb716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В Москве потребление импортного пива снизилось с 35 до 50 рублей мясо — от 200 до 400 человек . \n",
      "Что же касается российских военных баз в афганистане михаила лиходеяпогибли 14 человек в марокко и что делает их недостоверными . \n",
      "Представители правительства заявили что корпорация обязательно будет участвовать и america online cnn netscape warner brothers sony music entertainment заставляет владельцев музыкальных магазинов продавать компакт-диски которые туристы очевидно слушали в дороге часов девять от встречи с и о том как манипулятивный бисексуальный школьник-ауткаст ко второму чтению в профильный комитет на доработку . \n",
      "Не могу комментировать поскольку был в ярости . \n",
      "Задержаны 26 человек поддерживавших\n"
     ]
    }
   ],
   "source": [
    "print('В Москве', generate_bi(matrix_news_bi, id2word_news, id2bigram_news,\n",
    "                                  bigram2id_news, start='в москве', n=100).replace('<end>', '\\n').replace('\\n ', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1b07669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "умные преступления всегда совершают индивидуальности и каждой ступеньке империи микки — от 1 300 фунтов . \n",
      "По сведениям оперативного дежурного мвд абхазии виолетта чуева подрыв автомашины квалифицируется как особо тяжкое преступление . \n",
      "Нам не понадобится введения никакого чрезвычайного положения президент может распустить парламент и захватить его . \n",
      "Затем подельники садились в машину и уехали в вологду поздравить наших мам и там же где и предполагается что он пытался переправить в чечню . \n",
      "Соответствующий приказ подписал в среду приблизительно в полтора раза . \n",
      "Как сообщает риа новости ужесточен контроль за перевозками цветного лома на автотранспорте . \n",
      "В основном вице-премьеры иминистры которые\n"
     ]
    }
   ],
   "source": [
    "print(generate_bi(matrix_news_bi, id2word_news, id2bigram_news,\n",
    "                  bigram2id_news, start='<start> <start>', n=100).replace('<end>', '\\n').replace('\\n ', '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372ad10a",
   "metadata": {},
   "source": [
    "### Подсчёт перплексии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbbf4593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(logp, N):\n",
    "    return np.exp((-1/N) * logp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e941eff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_joint_proba(text, word_probas):\n",
    "    prob = 0\n",
    "    tokens = normalize(text)\n",
    "    for word in tokens:\n",
    "        if word in word_probas:\n",
    "            prob += (np.log(word_probas[word]))\n",
    "        else:\n",
    "            prob += np.log(2e-4)\n",
    "    \n",
    "    return prob, len(tokens)\n",
    "\n",
    "\n",
    "def compute_join_proba_markov_assumption(text, bigram_counts, trigram_counts):\n",
    "    prob = 0\n",
    "    tokens = normalize(text)\n",
    "    for ngram in ngrammer(['<start>', '<start>'] + tokens + ['<end>']):\n",
    "        i = (ngram[::-1].index(' ') + 1) * -1\n",
    "        bigram = ngram[:i]\n",
    "        if bigram in bigram_counts and ngram in bigram_counts:\n",
    "            prob += np.log(trigram_counts[ngram]/bigram_counts[bigram])\n",
    "        else:\n",
    "            prob += np.log(2e-5)\n",
    "    \n",
    "    return prob, len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe1d88c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = open('additional_sent.txt', encoding='utf-8').read()\n",
    "dev = dev.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7df7f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = 'В Москве потребление импортного пива снизилось с 35 до 50 рублей мясо — от 200 до 400 человек'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23fbe318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166371.05959946275"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(*compute_join_proba_markov_assumption(phrase, bigrams_news, trigrams_news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dbcb3010",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = []\n",
    "for sent in dev:\n",
    "    prob, N = compute_join_proba_markov_assumption(sent, bigrams_news, trigrams_news)\n",
    "    if not N:\n",
    "        continue\n",
    "    ps.append(perplexity(prob, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ffb5ba92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198176.28026769587"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb45c27",
   "metadata": {},
   "source": [
    "1. Сначала подсчитаем перплексию на одном из сгенерированных текстов\n",
    "\n",
    "2. Затем среднюю перплексию на 25 отложенных предложениях.\n",
    "\n",
    "Вывод: можно видеть, что результаты получаются примерно похожи."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeae5375",
   "metadata": {},
   "source": [
    "### Эксперимент с матрицей биграмы на биграмы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04d6f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_news = Counter()\n",
    "fourgrams_news = Counter()\n",
    "\n",
    "for sentence in sentences_news:\n",
    "    bigrams_news.update(ngrammer(sentence))\n",
    "    fourgrams_news.update(ngrammer(sentence, n=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdd717d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_news_bi = lil_matrix((len(bigrams_news), \n",
    "                        len(bigrams_news)))\n",
    "\n",
    "id2bigram_news = list(bigrams_news)\n",
    "bigram2id_news = {word:i for i, word in enumerate(id2bigram_news)}\n",
    "\n",
    "for ngram in fourgrams_news:\n",
    "    bigram1 = ' '.join(ngram.split()[:2])\n",
    "    bigram2 = ' '.join(ngram.split()[2:])\n",
    "    matrix_news_bi[bigram2id_news[bigram1], \n",
    "                   bigram2id_news[bigram2]] = (fourgrams_news[ngram] / bigrams_news[bigram1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c6057c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bi(matrix, id2word, word2id, start, n=100):\n",
    "    text = []\n",
    "    current_idx = word2id[start]\n",
    "    upper = False\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        try:\n",
    "            chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx].toarray()[0])\n",
    "        except ValueError:\n",
    "            text.append('...')\n",
    "            break\n",
    "        \n",
    "        if upper:\n",
    "            text.append(id2word[chosen].title())\n",
    "            upper = False\n",
    "        elif '<end>' in id2word[chosen]:\n",
    "            text.extend([id2word[chosen], '.'])\n",
    "            chosen = word2id['<start> <start>']\n",
    "            upper = True\n",
    "        else:\n",
    "            text.append(id2word[chosen]) \n",
    "            \n",
    "        current_idx = chosen\n",
    "    \n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60580884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "новейшие продукты современной электроники он с апреля этого года когда начал испытывать трудности с хлебом существуют по всей стране с частным визитом ...\n"
     ]
    }
   ],
   "source": [
    "print(generate_bi(matrix_news_bi, id2bigram_news, bigram2id_news, start='<start> <start>', n=100).replace('<end>', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ae2a5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Как сообщает bbc в субботу во время телефонного разговора с шахтерами она даже спускалась в шахту несмотря на многочисленные требования собравшихся никто из правления ао к ним не съездишь а жаль  . За Прошлый год не более 60-70 километров  . Однако Многие сотрудники оон покидают афганистан из-за серии нападений на инкассаторов  . — Ты же я недавно переехавший в москву ...\n"
     ]
    }
   ],
   "source": [
    "print('Как сообщает',\n",
    "      generate_bi(matrix_news_bi, id2bigram_news, bigram2id_news, start='как сообщает', n=100).replace('<end>', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f19afe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "По данным наших источников именно боевики заставляют мирных жителей возвращаться в грозный ...\n"
     ]
    }
   ],
   "source": [
    "print('По данным',\n",
    "      generate_bi(matrix_news_bi, id2bigram_news, bigram2id_news, start='по данным', n=100).replace('<end>', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0db76d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "По данным эха москвы с раннего утра привычно выстроились с плакатами у дома правительства в зданиях судов нет рукопись романа тихий дон ...\n"
     ]
    }
   ],
   "source": [
    "print('По данным',\n",
    "      generate_bi(matrix_news_bi, id2bigram_news, bigram2id_news, start='по данным', n=100).replace('<end>', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1adddd",
   "metadata": {},
   "source": [
    "С матрицей биграмы на биграмы тексты получаются более связными, но из-за учитывания только частотности модель может резко менять тему. Также без сглаживания и обработки незнакомых слов модель быстро прекращает генерацию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0a8dd5",
   "metadata": {},
   "source": [
    "## Задание № 2* (2 балла). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b36c44b",
   "metadata": {},
   "source": [
    "Прочитайте главу про языковое моделирование в книге Журафски и Мартина - https://web.stanford.edu/~jurafsky/slp3/3.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b1bd8",
   "metadata": {},
   "source": [
    "Развернуто (в пределах 1000 знаков) ответьте на вопросы (по-русски):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2cf844",
   "metadata": {},
   "source": [
    "1. Что можно делать с проблемой несловарных слов? В семинаре мы просто использовали какое-то маленькое значение вероятности, а какие есть другие способы?\n",
    "\n",
    "- создать систему \"открытого словаря\", то есть иначе - заменять незнакомые слова **тестовой выборки** на какой-нибудь тег, например, \\<unk>. \n",
    "\n",
    "Как в этом случае мы зададим вероятность данного тега? - 1) задать словарь токенов на обучающей выборке, 2) нормализовать тестовые данные по фиксированному словарю обучающей выборки, заменив отсутствующие слова тегом \\<unk>, 3) обновить вероятности с учетом данного тега\n",
    "\n",
    "- заменять тегом \\<unk> случайные слова в обучающей выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d1c152",
   "metadata": {},
   "source": [
    "2. Что такое сглаживание (smoothing)?\n",
    "\n",
    "Сглаживание - это техника, которая нужна, чтобы модель также распознавала уже знакомые слова, но в незнакомых контекстах. Есть разные виды сглаживания `Laplace (add-one) smoothing, add-k smoothing, stupid backoff, and Kneser-Ney smoothing.`\n",
    "\n",
    "В простейшем случае можно добавить 1 к частотности каждой нграмы. Тогда нграмы, ни разу не встретившиеся в корпусе, теперь будут иметь частотность 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
