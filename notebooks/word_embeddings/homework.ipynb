{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cde5fd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1f5499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('wiki_data.txt', names=['text'], sep='\\t', on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a77b9b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20002, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c422aa0",
   "metadata": {},
   "source": [
    "# Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a72790",
   "metadata": {},
   "source": [
    "Обучите word2vec модели с негативным семплированием (cbow и skip-gram) с помощью tensorflow аналогично тому, как это было сделано в семинаре. Вам нужно изменить следующие пункты: \n",
    "1) добавьте лемматизацию в предобработку (любым способом)  \n",
    "2) измените размер окна на 6 для cbow и 12 для skip gram (обратите внимание, что размер окна = #слов слева + #слов справа, в gen_batches в семинаре window используется не так и вам нужно это  изменить!)  \n",
    "\n",
    "Выберете несколько не похожих по смыслу слов, и протестируйте полученные эмбединги (найдите ближайшие слова и оцените правильность, как в семинаре)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b361452a",
   "metadata": {},
   "source": [
    "**Лемматизируем тексты**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7716280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer(lang='ru')\n",
    "storage = {}\n",
    "\n",
    "def lemma_generator(tokens: list) -> list:\n",
    "    global storage\n",
    "    lemma = ''\n",
    "    for tok in tokens:\n",
    "        if tok.isalpha():\n",
    "            if not tok in storage:\n",
    "                lemma = morph.parse(tok)[0].normal_form\n",
    "                storage[tok] = lemma\n",
    "            else:\n",
    "                lemma = storage[tok]\n",
    "            yield lemma\n",
    "\n",
    "def text_to_lemma(s: str) -> str:\n",
    "    global morph\n",
    "    tokens = wordpunct_tokenize(s)\n",
    "    return ' '.join(list(lemma_generator(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f71d7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['lemma'] = data.text.apply(text_to_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06c8b317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    новостройка нижегородский область новострый йк...\n",
       "1    эсмеральда фильм эсмеральда немой короткометра...\n",
       "2    список остров архипелаг норденшёльд это рабочи...\n",
       "3    минкин ми нкина ми нкина фамилия получить расп...\n",
       "4    пероральный приём лекарственный средство перор...\n",
       "Name: lemma, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.lemma.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2862b9a8",
   "metadata": {},
   "source": [
    "**Подготовка данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "75bb1de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vocab = Counter()\n",
    "\n",
    "for text in data.lemma:\n",
    "    vocab.update(text.split())\n",
    "    \n",
    "filtered_vocab = set([word for word in vocab if vocab[word] > 30])\n",
    "word2id = {word: i + 1 for i, word in enumerate(filtered_vocab)}\n",
    "word2id['PAD'] = 0\n",
    "id2word = {i: word for word, i in word2id.items()}\n",
    "        \n",
    "def text_in_idx_generator(texts):\n",
    "    global word2id\n",
    "    for l in texts:\n",
    "        yield [word2id[token] for token in l if token in word2id]\n",
    "        \n",
    "sentences = list(text_in_idx_generator(data.lemma.apply(str.split)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b0043a",
   "metadata": {},
   "source": [
    "**Вспомогательные функции**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "209630a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# skip gram\n",
    "def gen_batches_sg(sentences, window = 5, batch_size=1000):\n",
    "    while True:\n",
    "        X_target = []\n",
    "        X_context = []\n",
    "        y = []\n",
    "\n",
    "        for sent in sentences:\n",
    "            for i in range(len(sent)-1):\n",
    "                word = sent[i]\n",
    "                context = sent[max(0, i-window):i] + sent[i+1:i+window]\n",
    "                for context_word in context:\n",
    "                    X_target.append(word)\n",
    "                    X_context.append(context_word)\n",
    "                    y.append(1)\n",
    "                    \n",
    "                    X_target.append(word)\n",
    "                    X_context.append(np.random.randint(vocab_size))\n",
    "                    y.append(0)\n",
    "                    \n",
    "                    if len(X_target) >= batch_size:\n",
    "                        X_target = np.array(X_target)\n",
    "                        X_context = np.array(X_context)\n",
    "                        y = np.array(y)\n",
    "                        yield ((X_target, X_context), y)\n",
    "                        X_target = []\n",
    "                        X_context = []\n",
    "                        y = []\n",
    "\n",
    "# # cbow \n",
    "def gen_batches_cbow(sentences, window = 5, batch_size=1000):\n",
    "    while True:\n",
    "        X_target = []\n",
    "        X_context = []\n",
    "        y = []\n",
    "\n",
    "        for sent in sentences:\n",
    "            for i in range(len(sent)-1):\n",
    "                word = sent[i]\n",
    "                context = sent[max(0, i-window):i] + sent[i+1:i+window]\n",
    "\n",
    "                X_target.append(word)\n",
    "                X_context.append(context)\n",
    "                y.append(1)\n",
    "                \n",
    "                X_target.append(np.random.randint(vocab_size))\n",
    "                X_context.append(context)\n",
    "                y.append(0)\n",
    "\n",
    "                if len(X_target) == batch_size:\n",
    "                    X_target = np.array(X_target)\n",
    "                    X_context = tf.keras.preprocessing.sequence.pad_sequences(X_context, maxlen=window*2)\n",
    "                    y = np.array(y)\n",
    "                    yield ((X_target, X_context), y)\n",
    "                    X_target = []\n",
    "                    X_context = []\n",
    "                    y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3c3a5172",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074d2aae",
   "metadata": {},
   "source": [
    "**CBOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "78800045",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_target = tf.keras.layers.Input(shape=(1,))\n",
    "inputs_context = tf.keras.layers.Input(shape=(10,))\n",
    "\n",
    "embeddings_target = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_target, )\n",
    "embeddings_context = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_context, )\n",
    "\n",
    "target = tf.keras.layers.Flatten()(embeddings_target)\n",
    "context = tf.keras.layers.Lambda(lambda x: tf.keras.backend.sum(x, axis=1))(embeddings_context)\n",
    "dot = tf.keras.layers.Dot(1)([target, context])\n",
    "\n",
    "outputs = tf.keras.layers.Activation(activation='sigmoid')(dot)\n",
    "\n",
    "model = tf.keras.Model(inputs=[inputs_target, inputs_context], \n",
    "                       outputs=outputs)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d3ca0df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2500/2500 [==============================] - 250s 100ms/step - loss: 0.2694 - accuracy: 0.8876 - val_loss: 0.3000 - val_accuracy: 0.8775\n",
      "Epoch 2/3\n",
      "2500/2500 [==============================] - 249s 100ms/step - loss: 0.2917 - accuracy: 0.8812 - val_loss: 0.2692 - val_accuracy: 0.8914\n",
      "Epoch 3/3\n",
      "2500/2500 [==============================] - 248s 99ms/step - loss: 0.2725 - accuracy: 0.8902 - val_loss: 0.2750 - val_accuracy: 0.8894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x220fde9e0a0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(gen_batches_cbow(sentences[:19000], window=6),\n",
    "          validation_data=gen_batches_cbow(sentences[19000:],  window=6),\n",
    "          batch_size=1000,\n",
    "          steps_per_epoch=2500,\n",
    "          validation_steps=30,\n",
    "          epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec79c3a",
   "metadata": {},
   "source": [
    "**Skip-gram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7157eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_target = tf.keras.layers.Input(shape=(1,))\n",
    "inputs_context = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "embeddings_target = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_target, )\n",
    "embeddings_context = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_context, )\n",
    "\n",
    "target = tf.keras.layers.Flatten()(embeddings_target)\n",
    "context = tf.keras.layers.Flatten()(embeddings_context)\n",
    "\n",
    "dot = tf.keras.layers.Dot(1)([target, context])\n",
    "outputs = tf.keras.layers.Activation(activation='sigmoid')(dot)\n",
    "\n",
    "model_sg = tf.keras.Model(inputs=[inputs_target, inputs_context], \n",
    "                       outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model_sg.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "144cf029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2500/2500 [==============================] - 232s 92ms/step - loss: 0.5016 - accuracy: 0.7565 - val_loss: 0.5265 - val_accuracy: 0.7468\n",
      "Epoch 2/3\n",
      "2500/2500 [==============================] - 229s 92ms/step - loss: 0.4555 - accuracy: 0.7922 - val_loss: 0.5057 - val_accuracy: 0.7884\n",
      "Epoch 3/3\n",
      "2500/2500 [==============================] - 232s 93ms/step - loss: 0.4577 - accuracy: 0.7959 - val_loss: 0.5718 - val_accuracy: 0.7539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2208401c580>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sg.fit(gen_batches_sg(sentences[:19000], window=12),\n",
    "             validation_data=gen_batches_sg(sentences[19000:],  window=12),\n",
    "             batch_size=1000,\n",
    "             steps_per_epoch=2500,\n",
    "             validation_steps=30,\n",
    "             epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d6140c",
   "metadata": {},
   "source": [
    "**Оценка эмбеддингов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b9cc887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "def most_similar(word, cbow, skipgram, n=5):\n",
    "    global id2word, word2id\n",
    "    similar_cbow = [id2word[i] for i in \n",
    "                    cosine_distances(cbow[word2id[word]].reshape(1, -1), cbow).argsort()[0][:n]]\n",
    "    similar_sg = [id2word[i] for i in \n",
    "                    cosine_distances(skipgram[word2id[word]].reshape(1, -1), skipgram).argsort()[0][:n]]\n",
    "    print(f\"{word}\\nCBOW-similar: {similar_cbow}\\nSkip-gram: {similar_sg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "46ddf687",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_cbow = model.layers[2].get_weights()[0]\n",
    "embeddings_sg = model_sg.layers[2].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7e920395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "университет\n",
      "CBOW-similar: ['университет', 'институт', 'студент', 'школа', 'академия', 'факультет', 'научный', 'училище', 'кафедра', 'колледж']\n",
      "Skip-gram: ['университет', 'нарвский', 'курс', 'кафедра', 'петроградский', 'вступить', 'декабрь', 'приезжать', 'братский', 'руководитель']\n"
     ]
    }
   ],
   "source": [
    "most_similar('университет', embeddings_cbow, embeddings_sg, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "287a2431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "красный\n",
      "CBOW-similar: ['красный', 'белый', 'зелёный', 'чёрный', 'цвет', 'большой', 'сторона', 'орёл', 'и', 'звезда']\n",
      "Skip-gram: ['красный', 'хлопин', 'действительно', 'мёртвый', 'солнце', 'семён', 'раствор', 'факт', 'оружие', 'отсчёт']\n"
     ]
    }
   ],
   "source": [
    "most_similar('красный', embeddings_cbow, embeddings_sg, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d78e3260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "женщина\n",
      "CBOW-similar: ['женщина', 'мужчина', 'женский', 'ребёнок', 'девушка', 'одежда', 'костюм', 'лицо', 'трое', 'картина']\n",
      "Skip-gram: ['женщина', 'швеция', 'соревнование', 'лос', 'пробиться', 'закончиться', 'страна', 'интервью', 'парусный', 'долгосрочный']\n"
     ]
    }
   ],
   "source": [
    "most_similar('женщина', embeddings_cbow, embeddings_sg, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b42d92",
   "metadata": {},
   "source": [
    "Как видно, CBOW (также имея в виду его меньшее контекстное окно) предсказывает слова, которые могли бы заместить целевое слово синтаксически (семантически слова близки лишь отчасти, поскольку относятся к одной группе вроде *цвета* или *люди*)\n",
    "\n",
    "    университет = институт\n",
    "    красный = белый = зелёный = чёрный \n",
    "    женщина = мужчина = ребёнок = девушка\n",
    "    \n",
    "Тогда как Skip-gram показывает слова, которые находятся рядом с целевым словом, что хорошо видно на примере слова *университет*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b61b7c",
   "metadata": {},
   "source": [
    "# Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eff080",
   "metadata": {},
   "source": [
    "Обучите 1 word2vec и 1 fastext модель в gensim. В каждой из модели нужно задать все параметры, которые мы разбирали на семинаре. Заданные значения должны отличаться от дефолтных и от тех, что мы использовали на семинаре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6a6aa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "135c2291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# CBOW with negative sampling\n",
    "w2v = gensim.models.Word2Vec(data.lemma.apply(str.split), \n",
    "                             vector_size=100, \n",
    "                             min_count=30, \n",
    "                             max_vocab_size=20000,\n",
    "                             window=6,\n",
    "                             epochs=10,\n",
    "                             hs=0,\n",
    "                             negative=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "986c2018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('утром', 0.7718522548675537),\n",
       " ('ночь', 0.7375233769416809),\n",
       " ('вечером', 0.7304009795188904),\n",
       " ('час', 0.7204369306564331),\n",
       " ('вечер', 0.6180065870285034),\n",
       " ('ночью', 0.6135960221290588),\n",
       " ('день', 0.608790934085846),\n",
       " ('минута', 0.5820714235305786),\n",
       " ('сутки', 0.5688872337341309),\n",
       " ('подступ', 0.5477177500724792)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('утро')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5035bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ft = gensim.models.FastText(data.lemma.apply(str.split), \n",
    "                            min_n=3, \n",
    "                            max_n=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "947f2074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('утром', 0.8683101534843445),\n",
       " ('дутро', 0.84256911277771),\n",
       " ('скороход', 0.6741518974304199),\n",
       " ('оса', 0.657135009765625),\n",
       " ('рм', 0.6513649225234985),\n",
       " ('лёд', 0.641215980052948),\n",
       " ('боезапас', 0.6369556784629822),\n",
       " ('дымоход', 0.6338866949081421),\n",
       " ('снегоход', 0.6317901611328125),\n",
       " ('плацдарм', 0.6232016682624817)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.wv.most_similar('утро')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bb928c",
   "metadata": {},
   "source": [
    "# Задание 3 (4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3019b0d1",
   "metadata": {},
   "source": [
    "Используя датасет для классификации (labeled.csv) и простую нейронную сеть (последняя модель в семинаре), оцените качество полученных эмбедингов в задании 1 и 2 (4 набора эмбедингов), также проверьте 1 любую из предобученных моделей с rus-vectores (но только не tayga_upos_skipgram_300_2_2019). \n",
    "Какая модель показывает наилучший результат?\n",
    "\n",
    "Убедитесь, что для каждой модели вы корректно воспроизводите пайплайн предобработки (в 1 задании у вас лемматизация, не забудьте ее применить к датасету для классификации; у выбранной предобученной модели может быть своя специфичная предобработка - ее нужно воспроизвести)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ed908832",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic = pd.read_csv(\"labeled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "60c18c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic['lemma'] = toxic.comment.apply(text_to_lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06792063",
   "metadata": {},
   "source": [
    "**Обрабатываем лемматизированные данные**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ffaef14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "for text in toxic.lemma:\n",
    "    vocab.update(text.split())\n",
    "    \n",
    "filtered_vocab = set([word for word in vocab if vocab[word] > 30])\n",
    "word2id_1 = {word: i + 1 for i, word in enumerate(filtered_vocab)}\n",
    "word2id_1['PAD'] = 0\n",
    "id2word_1 = {i: word for word, i in word2id.items()}\n",
    "        \n",
    "X = list(text_in_idx_generator(toxic.lemma.apply(str.split)))\n",
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=100)\n",
    "y = toxic.toxic.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b2fb43",
   "metadata": {},
   "source": [
    "**Разбиваем их на обучающую и тестовую выборки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4e1bc6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3106828",
   "metadata": {},
   "source": [
    "**Учим модели, основанные на Word2Vec & FastText предобученных эмбеддингах (gensim)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bb748de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compiling_models(weights, vec_size=100):    \n",
    "    inputs = tf.keras.layers.Input(shape=(100,))\n",
    "    embeddings = tf.keras.layers.Embedding(input_dim=len(word2id_1), output_dim=vec_size, \n",
    "                                           trainable=True,\n",
    "                                           weights=[weights])(inputs, )\n",
    "    mean = tf.keras.layers.Lambda(lambda x: tf.keras.backend.mean(x, axis=1))(embeddings)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(mean)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6e45786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gensim_weights(model):\n",
    "    global word2id_1\n",
    "    weights = np.zeros((len(word2id_1), 100))\n",
    "    \n",
    "    for word, i in word2id_1.items():\n",
    "        if word == 'PAD':\n",
    "            continue\n",
    "        try:\n",
    "            weights[i] = model.wv[word]\n",
    "        except KeyError:\n",
    "            weights[i] = model.wv['а']\n",
    "            \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "24bb42ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_w = get_gensim_weights(w2v)\n",
    "ft_w = get_gensim_weights(ft)\n",
    "\n",
    "w2v_model = compiling_models(w2v_w)\n",
    "ft_model = compiling_models(ft_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4228f66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.6174 - accuracy: 0.6642 - val_loss: 0.5862 - val_accuracy: 0.6685\n",
      "Epoch 2/10\n",
      "214/214 [==============================] - 2s 7ms/step - loss: 0.5750 - accuracy: 0.6705 - val_loss: 0.5490 - val_accuracy: 0.6852\n",
      "Epoch 3/10\n",
      "214/214 [==============================] - 2s 7ms/step - loss: 0.5330 - accuracy: 0.7109 - val_loss: 0.5128 - val_accuracy: 0.7393\n",
      "Epoch 4/10\n",
      "214/214 [==============================] - 2s 7ms/step - loss: 0.4919 - accuracy: 0.7630 - val_loss: 0.4820 - val_accuracy: 0.7920\n",
      "Epoch 5/10\n",
      "214/214 [==============================] - 2s 7ms/step - loss: 0.4567 - accuracy: 0.7972 - val_loss: 0.4580 - val_accuracy: 0.8183\n",
      "Epoch 6/10\n",
      "214/214 [==============================] - 1s 7ms/step - loss: 0.4283 - accuracy: 0.8176 - val_loss: 0.4402 - val_accuracy: 0.8239\n",
      "Epoch 7/10\n",
      "214/214 [==============================] - 2s 7ms/step - loss: 0.4059 - accuracy: 0.8312 - val_loss: 0.4287 - val_accuracy: 0.8266\n",
      "Epoch 8/10\n",
      "214/214 [==============================] - 2s 7ms/step - loss: 0.3879 - accuracy: 0.8389 - val_loss: 0.4193 - val_accuracy: 0.8585\n",
      "Epoch 9/10\n",
      "214/214 [==============================] - 2s 7ms/step - loss: 0.3735 - accuracy: 0.8457 - val_loss: 0.4124 - val_accuracy: 0.8599\n",
      "Epoch 10/10\n",
      "214/214 [==============================] - 1s 7ms/step - loss: 0.3627 - accuracy: 0.8520 - val_loss: 0.4078 - val_accuracy: 0.8599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22086f994f0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=64,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "eb0b3ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "214/214 [==============================] - 3s 10ms/step - loss: 0.6143 - accuracy: 0.6639 - val_loss: 0.5998 - val_accuracy: 0.6685\n",
      "Epoch 2/10\n",
      "214/214 [==============================] - 2s 7ms/step - loss: 0.5870 - accuracy: 0.6685 - val_loss: 0.5809 - val_accuracy: 0.6713\n",
      "Epoch 3/10\n",
      "214/214 [==============================] - 2s 7ms/step - loss: 0.5631 - accuracy: 0.6823 - val_loss: 0.5685 - val_accuracy: 0.7323\n",
      "Epoch 4/10\n",
      "214/214 [==============================] - 2s 7ms/step - loss: 0.5392 - accuracy: 0.7120 - val_loss: 0.5401 - val_accuracy: 0.7129\n",
      "Epoch 5/10\n",
      "214/214 [==============================] - 2s 7ms/step - loss: 0.5125 - accuracy: 0.7416 - val_loss: 0.5193 - val_accuracy: 0.7393\n",
      "Epoch 6/10\n",
      "214/214 [==============================] - 2s 7ms/step - loss: 0.4864 - accuracy: 0.7707 - val_loss: 0.5000 - val_accuracy: 0.7684\n",
      "Epoch 7/10\n",
      "214/214 [==============================] - 2s 7ms/step - loss: 0.4623 - accuracy: 0.7937 - val_loss: 0.4828 - val_accuracy: 0.7878\n",
      "Epoch 8/10\n",
      "214/214 [==============================] - 1s 7ms/step - loss: 0.4407 - accuracy: 0.8091 - val_loss: 0.4687 - val_accuracy: 0.8141\n",
      "Epoch 9/10\n",
      "214/214 [==============================] - 2s 7ms/step - loss: 0.4218 - accuracy: 0.8216 - val_loss: 0.4564 - val_accuracy: 0.7989\n",
      "Epoch 10/10\n",
      "214/214 [==============================] - 2s 7ms/step - loss: 0.4057 - accuracy: 0.8302 - val_loss: 0.4463 - val_accuracy: 0.8266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2208586df70>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=64,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b67692",
   "metadata": {},
   "source": [
    "**Учим модели, основанные на предобученных самостоятельно эмбеддингах**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b80ad738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(model):\n",
    "    global word2id, word2id_1\n",
    "    weights = np.zeros((len(word2id_1), 300))\n",
    "    \n",
    "    for word, i in word2id_1.items():\n",
    "        if word == 'PAD':\n",
    "            continue\n",
    "        try:\n",
    "            weights[i] = model[word2id['университет']]\n",
    "        except KeyError:\n",
    "            weights[i] = model[word2id['а']]\n",
    "            \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e6ddf559",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow = get_weights(embeddings_cbow)\n",
    "sg = get_weights(embeddings_sg)\n",
    "\n",
    "cbow_model = compiling_models(cbow, vec_size=300)\n",
    "sg_model = compiling_models(sg, vec_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1d5de824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "214/214 [==============================] - 5s 20ms/step - loss: 0.6140 - accuracy: 0.6649 - val_loss: 0.5865 - val_accuracy: 0.6699\n",
      "Epoch 2/10\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 0.5526 - accuracy: 0.6908 - val_loss: 0.5131 - val_accuracy: 0.7101\n",
      "Epoch 3/10\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 0.4604 - accuracy: 0.7903 - val_loss: 0.4509 - val_accuracy: 0.7975\n",
      "Epoch 4/10\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 0.3982 - accuracy: 0.8352 - val_loss: 0.4243 - val_accuracy: 0.8613\n",
      "Epoch 5/10\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 0.3653 - accuracy: 0.8509 - val_loss: 0.4107 - val_accuracy: 0.8502\n",
      "Epoch 6/10\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 0.3431 - accuracy: 0.8625 - val_loss: 0.4145 - val_accuracy: 0.8641\n",
      "Epoch 7/10\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 0.3287 - accuracy: 0.8656 - val_loss: 0.4038 - val_accuracy: 0.8627\n",
      "Epoch 8/10\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 0.3176 - accuracy: 0.8693 - val_loss: 0.4037 - val_accuracy: 0.8516\n",
      "Epoch 9/10\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 0.3096 - accuracy: 0.8736 - val_loss: 0.4061 - val_accuracy: 0.8488\n",
      "Epoch 10/10\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 0.3030 - accuracy: 0.8741 - val_loss: 0.4040 - val_accuracy: 0.8447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x220f8602b80>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=64,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "35e08cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "214/214 [==============================] - 5s 20ms/step - loss: 0.6164 - accuracy: 0.6638 - val_loss: 0.5819 - val_accuracy: 0.6699\n",
      "Epoch 2/10\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 0.5432 - accuracy: 0.7002 - val_loss: 0.5038 - val_accuracy: 0.7198\n",
      "Epoch 3/10\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 0.4497 - accuracy: 0.7996 - val_loss: 0.4442 - val_accuracy: 0.7961\n",
      "Epoch 4/10\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 0.3901 - accuracy: 0.8405 - val_loss: 0.4183 - val_accuracy: 0.8544\n",
      "Epoch 5/10\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 0.3591 - accuracy: 0.8562 - val_loss: 0.4078 - val_accuracy: 0.8530\n",
      "Epoch 6/10\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 0.3386 - accuracy: 0.8620 - val_loss: 0.4071 - val_accuracy: 0.8613\n",
      "Epoch 7/10\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 0.3251 - accuracy: 0.8657 - val_loss: 0.4034 - val_accuracy: 0.8655\n",
      "Epoch 8/10\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 0.3156 - accuracy: 0.8704 - val_loss: 0.4052 - val_accuracy: 0.8669\n",
      "Epoch 9/10\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 0.3057 - accuracy: 0.8742 - val_loss: 0.4069 - val_accuracy: 0.8599\n",
      "Epoch 10/10\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 0.3006 - accuracy: 0.8742 - val_loss: 0.4052 - val_accuracy: 0.8641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x220fe47d310>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=64,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffe61da",
   "metadata": {},
   "source": [
    "**Учим модель с rus-vectores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c10248a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruscor_model = gensim.models.KeyedVectors.load_word2vec_format(\"ruscorpora_upos_skipgram_300_5_2018.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3add23e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "\n",
    "m = Mystem()\n",
    "\n",
    "mapping = {}\n",
    "for line in open('./ru-rnc.map'):\n",
    "    ms, ud = line.strip('\\n').split()\n",
    "    mapping[ms] = ud\n",
    "\n",
    "def get_weights_pretrained_model(model):\n",
    "    global word2id_1, m, mapping, pos_word_storage\n",
    "    weights = np.zeros((len(word2id_1), 300))\n",
    "    norm_words = m.analyze(' '.join(word2id_1.keys()))\n",
    "    \n",
    "    for word, i in word2id_1.items():\n",
    "        if word == 'PAD':\n",
    "            continue\n",
    "        pos = 'UNKN'\n",
    "        if 'analysis' in norm_words[i-1] and len(norm_words[i-1][\"analysis\"]) > 1:\n",
    "            pos1 = norm_words[i-1][\"analysis\"][0][\"gr\"].split(',')[0]\n",
    "            if pos1 in mapping:\n",
    "                pos = mapping[pos1]\n",
    "        try:\n",
    "            weights[i] = model[f\"{word}_{pos}\"]\n",
    "        except KeyError:\n",
    "            weights[i] = ruscor_model['штука_NOUN']\n",
    "            \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "13a52a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruscor = get_weights_pretrained_model(ruscor_model)\n",
    "rc_model = compiling_models(ruscor, vec_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "84381a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.6179 - accuracy: 0.6627 - val_loss: 0.5850 - val_accuracy: 0.6699\n",
      "Epoch 2/10\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.5444 - accuracy: 0.6956 - val_loss: 0.5032 - val_accuracy: 0.7393\n",
      "Epoch 3/10\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.4494 - accuracy: 0.8000 - val_loss: 0.4442 - val_accuracy: 0.8502\n",
      "Epoch 4/10\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.3898 - accuracy: 0.8393 - val_loss: 0.4203 - val_accuracy: 0.8599\n",
      "Epoch 5/10\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.3573 - accuracy: 0.8551 - val_loss: 0.4147 - val_accuracy: 0.8599\n",
      "Epoch 6/10\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.3379 - accuracy: 0.8644 - val_loss: 0.4053 - val_accuracy: 0.8655\n",
      "Epoch 7/10\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.3253 - accuracy: 0.8660 - val_loss: 0.4047 - val_accuracy: 0.8613\n",
      "Epoch 8/10\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.3137 - accuracy: 0.8714 - val_loss: 0.4073 - val_accuracy: 0.8627\n",
      "Epoch 9/10\n",
      "214/214 [==============================] - 3s 13ms/step - loss: 0.3059 - accuracy: 0.8752 - val_loss: 0.4077 - val_accuracy: 0.8613\n",
      "Epoch 10/10\n",
      "214/214 [==============================] - 3s 12ms/step - loss: 0.2996 - accuracy: 0.8760 - val_loss: 0.4044 - val_accuracy: 0.8613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x220fa48ec40>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc_model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=64,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb4f628",
   "metadata": {},
   "source": [
    "**Сравним результаты**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "13088958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "49b95c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC Natalya\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4487699123385805"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_valid, predicted, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1cc102d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step\n",
      "23/23 [==============================] - 0s 2ms/step\n",
      " 1/23 [>.............................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC Natalya\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC Natalya\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step\n",
      "23/23 [==============================] - 0s 3ms/step\n",
      " 1/23 [>.............................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC Natalya\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\PC Natalya\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC Natalya\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "models = {'w2v': w2v_model, 'fasttext': ft_model, 'cbow': cbow_model, 'skipgram': sg_model, 'rus-vectores': rc_model}\n",
    "\n",
    "def score_generator():\n",
    "    global models, X_valid, y_valid\n",
    "    for name, model in models.items():\n",
    "        predicted = model.predict(X_valid)\n",
    "        predicted = np.argmax(predicted, axis=1)\n",
    "        precision = precision_score(y_valid, predicted, average='weighted')\n",
    "        recall = recall_score(y_valid, predicted, average='weighted')\n",
    "        f1 = f1_score(y_valid, predicted, average='weighted')\n",
    "        yield (name, precision, recall, f1)\n",
    "        \n",
    "scores = {'precision': [],\n",
    "          'recall': [],\n",
    "          'f1': []}\n",
    "idx = []\n",
    "\n",
    "for name, precision, recall, f1 in score_generator():\n",
    "    scores['precision'].append(precision)\n",
    "    scores['recall'].append(recall)\n",
    "    scores['f1'].append(f1)\n",
    "    idx.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "2f93eea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>w2v</th>\n",
       "      <td>0.44877</td>\n",
       "      <td>0.669903</td>\n",
       "      <td>0.53748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fasttext</th>\n",
       "      <td>0.44877</td>\n",
       "      <td>0.669903</td>\n",
       "      <td>0.53748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cbow</th>\n",
       "      <td>0.44877</td>\n",
       "      <td>0.669903</td>\n",
       "      <td>0.53748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skipgram</th>\n",
       "      <td>0.44877</td>\n",
       "      <td>0.669903</td>\n",
       "      <td>0.53748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rus-vectores</th>\n",
       "      <td>0.44877</td>\n",
       "      <td>0.669903</td>\n",
       "      <td>0.53748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall       f1\n",
       "w2v             0.44877  0.669903  0.53748\n",
       "fasttext        0.44877  0.669903  0.53748\n",
       "cbow            0.44877  0.669903  0.53748\n",
       "skipgram        0.44877  0.669903  0.53748\n",
       "rus-vectores    0.44877  0.669903  0.53748"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(scores, index=idx)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fd6294",
   "metadata": {},
   "source": [
    "**Результаты работы моделей одинаковы**, поскольку все они предсказывают только 0-вой класс"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
