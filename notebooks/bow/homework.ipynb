{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20f786e",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "129c4d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4314de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv/labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbffbbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>В спорт зал похожу тогда и зеркало можно. А по...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>Позвольте узнать, скольких детей вы воспитали,...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>Не дает на 4м свидании-не стоит тратить время.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>Мне похер на оценки.Всегда пишу то,что думаю.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>Передайте , который меня в чс кинул, что это н...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>А сейчас там ботов больше чем живых, по сути т...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  toxic\n",
       "1010  В спорт зал похожу тогда и зеркало можно. А по...    0.0\n",
       "1011  Позвольте узнать, скольких детей вы воспитали,...    0.0\n",
       "1012     Не дает на 4м свидании-не стоит тратить время.    0.0\n",
       "1013      Мне похер на оценки.Всегда пишу то,что думаю.    0.0\n",
       "1014  Передайте , который меня в чс кинул, что это н...    0.0\n",
       "1015  А сейчас там ботов больше чем живых, по сути т...    0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[1010:1015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d2477b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0    0.66514\n",
       " 1.0    0.33486\n",
       " Name: toxic, dtype: float64,\n",
       " (14412, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.toxic.value_counts(normalize=True), data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c316ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf72d19",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a045e99",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способ заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4d453",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор (любой) с каждым из векторизаторов. Сравните метрики и выберите победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a07af34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from razdel import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a962a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "train_V_dt = vectorizer.fit_transform(train.comment)\n",
    "test_V_dt = vectorizer.transform(test.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5d1f556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=lambda x: [w.text for w in tokenize(x)])\n",
    "train_V_rt = vectorizer.fit_transform(train.comment)\n",
    "test_V_rt = vectorizer.transform(test.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ff7a0e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_for_dt = LogisticRegression(solver=\"liblinear\")\n",
    "LR_for_rt = LogisticRegression(solver=\"liblinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "78135c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_for_dt.fit(train_V_dt, train.toxic)\n",
    "LR_for_rt.fit(train_V_rt, train.toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "14614fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_on_Vdt = LR_for_dt.predict(test_V_dt)\n",
    "pred_on_Vrt = LR_for_rt.predict(test_V_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eaef1cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f3b1f133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.91      1069\n",
      "         1.0       0.70      0.87      0.78       373\n",
      "\n",
      "    accuracy                           0.87      1442\n",
      "   macro avg       0.82      0.87      0.84      1442\n",
      "weighted avg       0.89      0.87      0.87      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_on_Vdt, test.toxic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7cdfde3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.89      0.91      1036\n",
      "         1.0       0.75      0.85      0.80       406\n",
      "\n",
      "    accuracy                           0.88      1442\n",
      "   macro avg       0.84      0.87      0.86      1442\n",
      "weighted avg       0.89      0.88      0.88      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_on_Vrt, test.toxic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2408a875",
   "metadata": {},
   "source": [
    "Сравнивая classification_report для логистической регрессии, обученной на частотном векторайзере с дефолтным токенизатором и токенизатором razdel, видим, что последний показывает несколько лучшие результаты - чаще определяет токсичные тексты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3c896c",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcd27a3",
   "metadata": {},
   "source": [
    "Преобразуйте таблицу с абсолютными частотностями в семинарской тетрадке в таблицу с tfidf значениями. (Таблица - https://i.ibb.co/r5Nc2HC/abs-bow.jpg) Формула tfidf есть в семинаре на картнике с пояснениями на английском. \n",
    "Считать нужно в питоне. Формат итоговой таблицы может быть любым, главное, чтобы был код и можно было воспроизвести вычисления. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17137ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5b50abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# запишем предложения с рисунка\n",
    "sentences = ['я и ты', 'ты и я', 'я, я и только я', 'только не я', 'он']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e05806a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# токенизируем их\n",
    "sent_words = [re.findall(r'\\w+', t) for t in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83622252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вспомогательная функция для нахождения уникальных токенов\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8206faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['я', 'и', 'ты'],\n",
       " ['ты', 'и', 'я'],\n",
       " ['я', 'я', 'и', 'только', 'я'],\n",
       " ['только', 'не', 'я'],\n",
       " ['он']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ee4a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# находим уникальные токены\n",
    "unique_words = list(set(flatten(sent_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73e6bb5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['он', 'ты', 'я', 'только', 'не', 'и']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f1ea826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем матрицу из нулей для подсчета частоты слов\n",
    "tf_matrix = np.zeros((len(sentences), len(unique_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eeb513ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем частоту уникальных слов для каждого документа\n",
    "# i - индекс уникального слова\n",
    "# j - индекс документа\n",
    "for i in range(len(unique_words)):\n",
    "    for j in range(len(sent_words)):\n",
    "        tf_matrix[j][i] = sentences[j].count(unique_words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cac1730d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 0., 0., 1.],\n",
       "       [0., 1., 1., 0., 0., 1.],\n",
       "       [0., 0., 3., 1., 0., 1.],\n",
       "       [0., 0., 1., 1., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c556f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посчитаем idf каждого слова - возьмем логарифм от \n",
    "# частного кол-ва документов и вектора с кол-вом ненулевых частот для каждого слова\n",
    "idf = np.log(tf_matrix.shape[0] / sum(tf_matrix != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43e9ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# домножим матрицу тф на вектор идф\n",
    "tf_idf_matrix = tf_matrix * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42680088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.91629073 0.22314355 0.         0.         0.51082562]\n",
      " [0.         0.91629073 0.22314355 0.         0.         0.51082562]\n",
      " [0.         0.         0.66943065 0.91629073 0.         0.51082562]\n",
      " [0.         0.         0.22314355 0.91629073 1.60943791 0.        ]\n",
      " [1.60943791 0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b9076e",
   "metadata": {},
   "source": [
    "## Задание 3 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e25357",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de962ad",
   "metadata": {},
   "source": [
    "Требования к моделям:   \n",
    "а) один классификатор должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторайзера должны быть вручную заданы как минимум 5 параметров (можно ставить разные параметры tfidfvectorizer и countvectorizer)  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра (по возможности)  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  \n",
    "\n",
    "*random_seed не считается за параметр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac0a5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "666b18d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\PC\n",
      "[nltk_data]     Natalya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import TweetTokenizer, wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab0c025",
   "metadata": {},
   "source": [
    "Сравним два токенайзера и выберем наиболее подходящий на примере текста 1012 (тут интересно употребление дефиса вместо положенного тире)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "04ca56c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Не', 'дает', 'на', '4м', 'свидании-не', 'стоит', 'тратить', 'время', '.']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TweetTokenizer().tokenize(data.comment[1012])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "101b5a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Не',\n",
       " 'дает',\n",
       " 'на',\n",
       " '4м',\n",
       " 'свидании',\n",
       " '-',\n",
       " 'не',\n",
       " 'стоит',\n",
       " 'тратить',\n",
       " 'время',\n",
       " '.']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(data.comment[1012])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aa5a69",
   "metadata": {},
   "source": [
    "На данном примере лучше работает wordpunct_tokenize, поэтому выберем его. Но возможно, что TweetTokenizer где-то сработает лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04124ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_ru = nltk.corpus.stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d119d80f",
   "metadata": {},
   "source": [
    "Сначала обучим MultinomialNB на CountVectorizer, поскольку это наиболее классическое решение для текстовой классификации\n",
    "\n",
    "Параметров для модели MultinomialNB всего 3, и те лучше оставить дефолтными, поэтому их не трогаем. Настроим параметры для векторайзера:\n",
    "* минимальная частота слова в словаре 4,\n",
    "* \"значения частоты бинарны\" - 0/1,\n",
    "* токенизируем с помощью wordpunct_tokenize, который мы выбрали выше,\n",
    "* стоп-слова возьмем из nltk + знаки пунктуации,\n",
    "* игнорируем слова, встречающиеся более чем в 2% документов (качество модели особо не падает, нужно для определения токсичных слов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "425b4d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "puncts = list(string.punctuation)\n",
    "stop_words_ru = stop_words_ru.extend(puncts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0ebfd873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "8cb5547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(min_df=4, binary=True, tokenizer=wordpunct_tokenize, stop_words=stop_words_ru, max_df=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "4038586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cv = cv.fit_transform(train.comment)\n",
    "test_cv = cv.transform(test.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "745bd58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_count = MultinomialNB()\n",
    "NB_count.fit(train_cv, train.toxic)\n",
    "pred_toxic_cv = NB_count.predict(test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "90311fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.87      0.90      1036\n",
      "         1.0       0.71      0.84      0.77       406\n",
      "\n",
      "    accuracy                           0.86      1442\n",
      "   macro avg       0.82      0.86      0.84      1442\n",
      "weighted avg       0.87      0.86      0.86      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_toxic_cv, test.toxic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "466d9475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_count.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "9f04ca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "c1fd5003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(data=np.sort(NB_count.feature_log_prob_[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081b882b",
   "metadata": {},
   "source": [
    "**Топ-10 самых вероятных слов для токсичных текстов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "58e547fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "нахуй\n",
      "себя\n",
      "вас\n",
      "теперь\n",
      "хохлы\n",
      "хохлов\n",
      "ему\n",
      "себе\n",
      "пиздец\n"
     ]
    }
   ],
   "source": [
    "for arg in np.argsort(NB_count.feature_log_prob_[1])[:-10:-1]:\n",
    "    print(cv.get_feature_names_out()[arg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991c2fbb",
   "metadata": {},
   "source": [
    "**Топ-10 самых вероятных слов для нетоксичных текстов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "9a5d1d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "например\n",
      "знаю\n",
      "4\n",
      "пока\n",
      "стоит\n",
      "деньги\n",
      "вроде\n",
      "который\n",
      "всегда\n"
     ]
    }
   ],
   "source": [
    "for arg in np.argsort(NB_count.feature_log_prob_[0])[:-10:-1]:\n",
    "    print(cv.get_feature_names_out()[arg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b401e381",
   "metadata": {},
   "source": [
    "**Топ-10 самых токсичных текстов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "fd84dab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.0 Как известно, у Укр ины (т.е. окр ины), слепленной по пьяни на коленке во 2-м десятилетии XX в., нет истории до XX столетия. Все земли, которые сейчас занимает Укр ина, это русские, румынские, польские и венгерские земли. Напоминаем, что укр инство это сугубо левацкая, антиконсервативная местечково-хуторская идеология, направленная, как и прочие левацкие идеи, на разделение больших наций и поддержание диктата интернацистов. Сторонники бандеровцев (леваков, выступавших за бесклассовое общество и борьбу с капитализмом) и карлика-душителя котов Степана Бандеры, который, как известно, боролся с расизмом, поддерживал Идель-Урал и называл побратимами исламских борцов за свободу из Азербайджана, не пользуются симпатиями у правых европейцев. И это правильно. Попытки заявить о некой отдельной нации неких украинцев это манипуляции, созданные с целью оторвать от русских часть их этнических земель и ослабить в будущем Россию. Только так, чудовищной ложью и тотальной пропагандой, фейковая нация укр инцев , слепленная советскими кукловодами из русских Юга и Киевщины, галичан, поляков, советских румын, славянизированных гуцулов, закарпатских венгров, евреев, татар и многонациональных советских новиопов (а ля Бабченко), может обрести жизнь на русских этнических землях. Разумеется, нет никакого народа укр инцев , как бы одно соседнее failed state ни пыталось их вывести из русских путём обмана, коверканья истории и откровенной фальсификации. Нынешний эксперимент по созданию некой украинской нации можно сравнить разве что с советским экспериментом по созданию нации советской на основании таких же мифов, фейков и откровенного бреда. И маниакальное желание снести все памятники выродку Ленину (Бланку) вас не должно обнадёживать. На смену ему устанавливают памятники такого же левацкого дегенерата-кошкодава Бандеры, чьи руки по локоть в славянской (прежде всего, польской) крови. Заместо совковой лжи про Великую революцию Октября пришла точно такая же наглая ложь про Великую революц ю Г дност абстрагируйтесь от фигуры блогера и посмотрите видео Чем в итоге завершился советский эксперимент, мы все знаем. Ждём закономерного итога эксперимента эльфийского (простите, укр инского ). Разумеется, зомбированные люди будут цепляться до последнего за свои мифы про отельный народ и чужих московитов , но всё это наваждение рано или поздно сгинет, как сгинул Совок со своей мощной идеологией, мифами и фейками.\n",
      "\n",
      "2 1.0 самый сброд червей-пидоров Не, ну если это черви-пидоры, то перечисленные тобой далее люди - это черви-пидоры в гуголплексе стаса какай просто Автор абсолютно неинтересного технического блога на Ютабе, пускай честного в отличие от Виласкома, но от того ничуть не менее унылого, любитель шутечек про куканы и поопускать маргиналов на тему не присаживал на них тёлку . соболева Говорящая голова народных масс, своего мнения не имеет, никогда в жизни не сделает ролик по какому-либо малооглашённому поводу, по хайповому не выскажет какую-либо точку зрения кроме той, которая будет угодно большинству. В жизни, по описанию очевидцев, быдловат. Продавал жопу Собянину, чем, ЧСХ, не может похвастаться никто из ОП-треда, кроме Хованского. амирана из дневника хача Никогда не понимал, кому он вообще нахуй нужен. Кому на полном серьёзе может доставлять наблюдать за жизнью мажора-рабовладельца, не сообщающего вам ничего полезного, или хотя бы как жить так же? Летсплеи на сто порядков более высокоинтеллектуальный и нужный контент, блеадь. Тоже продавал жопу Собянину. петушария Педофил-кремлебот, просто но комментс. гоблина Охуенный переводчик, но как человек говно. Указанные в ОП-треде личности определённо могут в интеллектуальные дискуссии, определённо не являются сцанными быдланами, и если и продают жопу, то только по праздникам. Несмотря на то что это неебаться борцуны с активной политической позицией, их борцунство почему-то только с совком, сралиным и члениным (которых нет) У Айтипедика немалая часть контента посвящена борьбе именно с текущей властью. и, на которых всем похуй кроме пары десятков тыщ сектантов Лол, ты рили не понимаешь, в чём тут соль? Тебе напомнить, что единственный человек, у которого рейтинг выше, чем у Пыни - это Сталин? 50 населения России в рот ебали Пыню и едро, но тащемта, хотели бы вернуться в Совок, потому их борцунство (благеров) преимущественно и с Совком.\n",
      "\n",
      "3 1.0 А сейчас смотрит хуйню всякую с пидорасом звоновым, В оправдание пидораса Звонова можно хотя бы сказать, что последний только и делал контент у чма на стримах: начиная с походов на спасс, новых гостей, научпопвидосов, заканчивая пародией на Что Где Когда. Вообще, после окончания лета я как-то переосмыслил свое отношение ко многим членам инвалидной конфы, да и к самому Маргиналу. Он часто пользуется контентом и талантами своих гостей, приглашая их за нихуя на стримы. При этом хуесосит их же за спиной и на других стримах, из-за чего всё, что гости в итоге получают в ответ за совместные стримы - это говно от маргинальных подписчиков у себя в фиде. И при этом Маргиналу хватает наглости потом ныть, что никто из нормальных людей к нему на стрим не хочет идти, увидав его стенку. Ему не приходит в голову, что поощряя токсичность в отношении своих оппонентов и гостей на стримах он, хотя и обретает ореол интеллектуального стримера, сливателя всяго и вся живого на руси, но по итогу все больше окукливается в собственной же аргументации и аудитории. Заметьте, что те, с кем он еще год назад дебатировал и спорил, сейчас просто избегают споров на стримах, просто не хотя засёра своей ленты (Левин тому ярчайщий пример. Или, уж простите, Звонов). Если раньше Маргоша был способен в самоиронию благодаря тем же убермемес, где замечали и косяки самого Маргинала, то с киком Льва Шойгу начался просто процесс окукливания. Теперь хуесосить Маргинала - запрещено, запрещено даже обсуждать и замечать тупость маргинала. Потому что, как говорит чмо: влияет на просмотры , ололо. По сути, запретив пятнать свою репутацию, но продолжая пятнать репутацию других (и друзей, и врагов) чмо сейчас пытается, сознательно или нет, построить образ эдакого интеллектуала-сливателя, каким бы мечтал стать Ларин. Только вот этот образ Маргинал пока попросту не заслужил. Недостаточно просто говорить ну это просто твое определение пиздец он дурак да, охуенно в ответ на аргументацию. Если раньше, причем, это было редкостью, то сейчас Маргинал совсем обленился и только так и дискутирует под улюлюканье анально модерируемого чатика. Safe space такой safe space.\n",
      "\n",
      "4 1.0 Стас, никому, кроме тебя и армии твоих подсосов(которые представляют собой типичный дегенеративный биомусор, ведущийся на любые скандалы-интриги), твои ролики нахуй не нужны. Серьёзно, ты сделал новости с целью показать, что такое говно может делать любой, а аудитория осталась на том же уровне, ведь людям извне ты не интересен. Да ещё и просит не подписываться, чтобы такую-то годноту ложкой хлебать подольше. Ты обосрался, стал посмешищем для абсолютно всех ютуберов, которые не являются полными ебланами. Тот же Хованский не ссыт тебе на ебало только потому, что ты вертишься с ним в одной компании, иногда даже лично пересекаетесь. Приятно было слышать, как он говорил, что отстреливался бы от таких, как ты, из огнестрела, стараясь забрать с собой побольше коммунистов, когда они придут его оаскулачиапть? Он открыто хуесосил людей и за меньшие грехи. Сложи 2 и 2, как он к тебе относится на самом деле. После чего ты сделал ещё более смешной ролик, где истеришь как побитая шлюха во время ПМС. Я ПОДЕБИЛ, А ЕСЛИ ВЫ НЕ ПОНЯЛИ ЭТОГО, ТО ВЫ ТУПЫЕ . Ты мог хотя бы сам его посмотреть перед заливом? Мне даже рофлить над тобой расхотелось, из смешного дегенерата, ты стал жалким дурачком. Это как смеятся над роликами, где контуженные ветераны пытаются ходить под клубную музыку. Над неполноценными смеятся плохо, даже стыдно стало. Я не утрирую. Просто посмотри на себя, Стас. Ну правда. Банишь людей в группе за лвйки и одно упоминание стрима. Ты делаешь всё, в чём самый отбитый и дегенеративный либераст обвиняет совок и сверкаешь разорванным очком. Никто тебя несправедливо не обсирал. Что на стриме по поводу дат, ну ты же сам проебался. На подкасте сообщил, что не будешь стримить. Если ты не был уверен, то зачем это говорить? А если был, почему не сообщил Маргиналу сразу же? Твоё слово в целом не стоит нихуя. Обещаешь не банить-куча удалённых комментов. Обещаешь стрим-не идёшь. Обещаешь что-то ещё, всегда проёбываешься, всё чаще на нарушение обещания тебе нужно в районе секунды-дня. Стоит ли удивлятся, что тебе за это прилетело? Когда то должно было. Ты сам срёшь себе в штаны, не злись, когда на это указывают пальцем.\n",
      "\n",
      "5 0.0 Возьмём как пример Россию, западноевропейские страны и США. Идёт метисация, сознательная политика замещения белого населения на пришлое черно-коричневое. Идёт создание новой расы метисов, исламизация и почернение. В крупных городах половина населения - выходцы из ебеней Мексики, Африки, Ближнего Востока, а в случае с Россией - Кавказа и Средней Азии. Этнические ниггеро-арабские гетто верят на хую законы как хотят, чудовищная по масштабам этническая преступность. Говорить о миграции и тем более затрагивать тему замещения коренного населения властями нельзя, иначе бутылка. Свобода слова тут не для вас, молодой человек. При этом говорить о том, что белые должны вымереть, и это нормально - можно. Белые официально вымирают ведётся пропаганда так или иначе направленная на снижение рождаемости белого населения. Феминизм, ЛГБТ, чайлдфри. Каждая женщина в Швеции - леволиберальная феминистка, это страна победившего феминизма. Что сегодня там происходит - страшно делается. Пропагандируются смешанные браки, межрасовые браки, пропагандируется превосходство детей-метисов. Идёт демонизация белых и пропаганда превосходства чёрных и смуглых мужчин, форс отношений белая женщина смуглый чёрный мужчина-мигрант. Как результат - всё больше чернильниц, всё больше смешанных браков, всё больше небелых метисов. Белые женщины просто не хотят контактировать с мужчинами своей нации и расы, наделяя их самыми плохими качествами и обожествляя черных. При этом большинство белых не считает завоз чурок чем-то плохим, наоборот, относятся к ним толерантно. Проводится политика насаждения толерантности, мультикультурализма, политкорректности и космополитизма. Набирающее популярность даже в России SJW - это вообще отдельная тема для обсуждения. Всё вышеперечисленное относится к сильнейшим когда-то странам, бывшим империям, нагибающим слабых. Сегодня происходит так, что бывшие империи в прямом смысле деградируют, вырождаются и вымирают, а место сильнейших когда-то, господствующих народов, занимают те, кого когда-то колонизировали. Во Франции к 2080 уже будут доминировать негры и арабы, в России - кавказцы и выходцы из средней Азии, в Великобритании - индийцы, негры, арабы, пакистанцы, etc. А в маленьких, нейтральных странах, вроде Словении или Беларуси, Литвы или Чехии, Румынии или Эстонии - всё пучком. Им вымирание не грозит, они остаются и будут оставаться белыми. Более того, у них ведётся политика, направленная на сохранение традиционных ценностей и культуры коренного населения. Они сказали беженцам нет . В Польшу, например, русскому или украинцу гораздо легче переехать и остаться, чем арабу или африканцу. В Германии ситуация противоположная, белых там не ждут. Польша, Чехия, Словакия, Венгрия, Словения, Хорватия, Сербия, БиГ, Черногория, Македония, Греция, Болгария, Румыния, Молдова, Украина, Беларусь, Литва, Латвия, Эстония - вот Европа будущего. Скандинавия, Южная, Западная Европа, а также Россия - лишатся коренного населения и своей культуры.\n",
      "\n",
      "6 1.0 Вот это реально черт опущенный. Хоть Гомикадзе Би и опущенный гей, которому на ебало ссали всем обществом, но он прав. Как бы не прискорбно было это признавать, но Гомик В Каске прав. Я бы очень хотел чтобы это было не так, но увы. А вот быть или хуй сосать - вот он черт и пиздабол, чисто мразь в мазке. Одна ложь и грязь. Просто пиздаболище. Ну вот реально одну хуйню несет. Вот он реально черт. Лучше уж ПиськаМазе чем вот это мразь в маске. Ноудискасс.\n",
      "\n",
      "7 1.0 Зальете шебм? Вот этот кун. Говорит, будто заявление забрали. Алсо как-то и не скажешь, что он станет совать хуй в очъко тян, а потом обмазывать ей губы, лол. Фу нахуй. Алсо, мне думается, что пиздит\n",
      "\n",
      "8 1.0 Сам хочу в Чехию в первую очередь из-за... нашествия хачей и чурок в Рашке. Это просто невыносимо нахуй стало, а тут Пыня оказывается ещё 10 лямов завезти хочет. Просто загоерлся желанием жить в белой моноэтничное стране среди братушек-славян. О, куколдофорсер-нацистик в треде.\n",
      "\n",
      "9 1.0 Уууууууууу, бляяяя. А он блядь заранее не знал, что у него будут съемки невротебаццаа каких то проектов, бухачи праздничные. Не любит он сука людей безответственных сам то епта послушай че ты пиздишь. Интересно ему про коммунизм послушать, твои верования потрошнут и катком переедут, сидит небось матчасть изучает.\n",
      "\n",
      "10 1.0 Я атеист и армянин. Просто рот твой ебал Лучше пусть чурки будут жидов резать, чем жиды вешать лапшу на уши\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for a in np.argsort(NB_count.predict_proba(test_cv)[:, 1])[:-11:-1]:\n",
    "    print(i, test.toxic[a], test.comment[a])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ee28ed",
   "metadata": {},
   "source": [
    "Тексты отобрались действительно токсичные. Тут без лишних комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c1d1de",
   "metadata": {},
   "source": [
    "Теперь обучим тоже простой алгоритм KNeighborsClassifier, используя векторайзер TfIdf\n",
    "\n",
    "Для TfIdf зададим\n",
    "* все тот же токенизатор,\n",
    "* все те же стоп-слова\n",
    "\n",
    "Для KNeighborsClassifier установим\n",
    "* количество соседей,\n",
    "* \"веса, инверсируемые по расстоянию\",\n",
    "* алгоритм поиска ближайших соседей - brute-force search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4bee5b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "09ffdb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiv = TfidfVectorizer(tokenizer=wordpunct_tokenize, stop_words=stop_words_ru, max_df=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "fd57fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tiv = tiv.fit_transform(train.comment)\n",
    "test_tiv = tiv.transform(test.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "7655efe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9, weights='distance', algorithm='brute')\n",
    "knn.fit(train_tiv, train.toxic)\n",
    "pred_toxic_tiv_knn = knn.predict(test_tiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "0c2117c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.81      0.87      1105\n",
      "         1.0       0.57      0.81      0.67       337\n",
      "\n",
      "    accuracy                           0.81      1442\n",
      "   macro avg       0.75      0.81      0.77      1442\n",
      "weighted avg       0.85      0.81      0.82      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_toxic_tiv_knn, test.toxic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90d93dc",
   "metadata": {},
   "source": [
    "**Топ-10 самых токсичных текстов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "70692429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.0 Хэллоуин 2018 года ведь шлак полный, и оценка у него 5.8.\n",
      "\n",
      "2 1.0 Опять хохлы из киберсотни на куриную косточку капчуют.\n",
      "\n",
      "3 1.0 Фильмы Груз 200 и Кочегар - смрад полный, только в голове психически нездорового человека может родиться такой сценарий.\n",
      "\n",
      "4 1.0 Хохол насиловал жертву около часа Вот это ебарь\n",
      "\n",
      "5 1.0 Зальете шебм? Вот этот кун. Говорит, будто заявление забрали. Алсо как-то и не скажешь, что он станет совать хуй в очъко тян, а потом обмазывать ей губы, лол. Фу нахуй. Алсо, мне думается, что пиздит\n",
      "\n",
      "6 1.0 Что-то не связал в единое: каратист - очкарик Пичужкин самка Эльцина (гори в аду тварь).\n",
      "\n",
      "7 1.0 Типа есть, чем думать. Лично мне жаль, что его не у бало, как следует. На премию Дарвина прямой кандидат.\n",
      "\n",
      "8 1.0 Стас, никому, кроме тебя и армии твоих подсосов(которые представляют собой типичный дегенеративный биомусор, ведущийся на любые скандалы-интриги), твои ролики нахуй не нужны. Серьёзно, ты сделал новости с целью показать, что такое говно может делать любой, а аудитория осталась на том же уровне, ведь людям извне ты не интересен. Да ещё и просит не подписываться, чтобы такую-то годноту ложкой хлебать подольше. Ты обосрался, стал посмешищем для абсолютно всех ютуберов, которые не являются полными ебланами. Тот же Хованский не ссыт тебе на ебало только потому, что ты вертишься с ним в одной компании, иногда даже лично пересекаетесь. Приятно было слышать, как он говорил, что отстреливался бы от таких, как ты, из огнестрела, стараясь забрать с собой побольше коммунистов, когда они придут его оаскулачиапть? Он открыто хуесосил людей и за меньшие грехи. Сложи 2 и 2, как он к тебе относится на самом деле. После чего ты сделал ещё более смешной ролик, где истеришь как побитая шлюха во время ПМС. Я ПОДЕБИЛ, А ЕСЛИ ВЫ НЕ ПОНЯЛИ ЭТОГО, ТО ВЫ ТУПЫЕ . Ты мог хотя бы сам его посмотреть перед заливом? Мне даже рофлить над тобой расхотелось, из смешного дегенерата, ты стал жалким дурачком. Это как смеятся над роликами, где контуженные ветераны пытаются ходить под клубную музыку. Над неполноценными смеятся плохо, даже стыдно стало. Я не утрирую. Просто посмотри на себя, Стас. Ну правда. Банишь людей в группе за лвйки и одно упоминание стрима. Ты делаешь всё, в чём самый отбитый и дегенеративный либераст обвиняет совок и сверкаешь разорванным очком. Никто тебя несправедливо не обсирал. Что на стриме по поводу дат, ну ты же сам проебался. На подкасте сообщил, что не будешь стримить. Если ты не был уверен, то зачем это говорить? А если был, почему не сообщил Маргиналу сразу же? Твоё слово в целом не стоит нихуя. Обещаешь не банить-куча удалённых комментов. Обещаешь стрим-не идёшь. Обещаешь что-то ещё, всегда проёбываешься, всё чаще на нарушение обещания тебе нужно в районе секунды-дня. Стоит ли удивлятся, что тебе за это прилетело? Когда то должно было. Ты сам срёшь себе в штаны, не злись, когда на это указывают пальцем.\n",
      "\n",
      "9 1.0 Смотрите, петух закукарекал. Пади падмойся, Маня\n",
      "\n",
      "10 1.0 Впервые солидарен С Милоновым Двачую, такая же хуйня. Реально гнать их нахуй из Рашки надо, пока не поздно еще! Вместе мы сможем спасти патриархат нашей любимой Россиюшки!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for a in np.argsort(knn.predict_proba(test_tiv)[:, 1])[:-11:-1]:\n",
    "    print(i, test.toxic[a], test.comment[a])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c211b7ed",
   "metadata": {},
   "source": [
    "Как и в прошлом случае, неправильно определен всего 1 текст. И он, как и в прошлом случае, сильно негативно окрашен и по словарю близок к токсичным текстам.\n",
    "\n",
    "Также можно отметить, что в обеих моделях есть схожие тексты в топе токсичности (например, 5 и 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f228c3e",
   "metadata": {},
   "source": [
    "## *Задание 4 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566929b7",
   "metadata": {},
   "source": [
    "Для классификаторов LogisticRegression и Random Forest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "efa329ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_tiv, train.toxic) # для train_tiv выше настроена фильтрация стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "73830a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "тебя\n",
      "хохлы\n",
      "хохлов\n",
      "тебе\n",
      "нахуй\n",
      "блять\n",
      "пиздец\n",
      "дебил\n",
      "блядь\n"
     ]
    }
   ],
   "source": [
    "for i in np.argsort(lr.coef_[0])[:-10:-1]:\n",
    "    print(tiv.get_feature_names_out()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "6c636315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced_subsample', max_depth=10,\n",
       "                       max_features='log2')"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RFC_tfidf = RandomForestClassifier(max_depth=10, max_features='log2', class_weight='balanced_subsample')\n",
    "RFC_tfidf.fit(train_tiv, train.toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "8cfa96a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "русские\n",
      "банк\n",
      "очень\n",
      "хохлов\n",
      "тебя\n",
      "много\n",
      "пиздец\n",
      "сука\n",
      "тебе\n"
     ]
    }
   ],
   "source": [
    "for j in np.argsort(RFC_tfidf.feature_importances_)[:-10:-1]:\n",
    "    print(tiv.get_feature_names_out()[j])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
